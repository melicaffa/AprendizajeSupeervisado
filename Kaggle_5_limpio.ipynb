{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "Kaggle_5_limpio.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYoOiEYXoSAJ",
        "colab_type": "text"
      },
      "source": [
        "# Diplodatos Kaggle Competition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeGzAToCoSAK",
        "colab_type": "text"
      },
      "source": [
        "We present this peace of code to create the baseline for the competition, and as an example of how to deal with these kind of problems. The main goals are that you:\n",
        "\n",
        "1. Learn\n",
        "1. Try different models and see which one fits the best the given data\n",
        "1. Get a higher score than the given one in the current baseline example\n",
        "1. Try to get the highest score in the class :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmzh-QKuoSAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the required packages\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import ensemble\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier as DT\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import preprocessing\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybqdvn85oSAQ",
        "colab_type": "text"
      },
      "source": [
        "Read the *original* dataset..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jgo1zUN-jWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from hashlib import md5\n",
        "def hashit(val):\n",
        "    if isinstance(val, float): \n",
        "        return str(val)\n",
        "    return md5(val.encode('utf-8')).hexdigest()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ymeq3W2P0SD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dia_laboral(nombre_dia):\n",
        "    if nombre_dia in ['Sunday', 'Saturday']: #['Wednesday', 'Thursday', 'Friday', 'Monday','Tuesday']:\n",
        "        #return 'Fin de semana'\n",
        "        return 1\n",
        "    else:\n",
        "        #return 'Dia laboral'\n",
        "        return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQCLhhEq2Tko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transform_data(train_data_fname, test_data_fname):\n",
        "    df_train = pd.read_csv(train_data_fname)\n",
        "    df_train['is_train_set'] = 1\n",
        "    df_test = pd.read_csv(test_data_fname)\n",
        "    df_test['is_train_set'] = 0\n",
        "\n",
        "##################################################################\n",
        "### NUEVO VERSION 3\n",
        "##################################################################\n",
        "    df_train['W']=df_train.Weekday.apply(lambda x:get_dia_laboral(x))\n",
        "    df_train.drop('Weekday', axis=1, inplace=True)\n",
        "    df_train.rename(columns={'W': 'Weekday'}, inplace=True)\n",
        "    #display(df_train.head(20))\n",
        "########\n",
        "    df_test['W']=df_test.Weekday.apply(lambda x:get_dia_laboral(x))\n",
        "    df_test.drop('Weekday', axis=1, inplace=True)\n",
        "    df_test.rename(columns={'W': 'Weekday'}, inplace=True)\n",
        "    #display(df_test.head(20))\n",
        "##################################################################\n",
        "\n",
        "    # we  get the TripType for the train set. To do that, we group by VisitNumber and\n",
        "    # then we get the max (or min or avg)\n",
        "    ######### PROBAR CAMBIANDO A MIN Y AVG...#################################\n",
        "    y = df_train.groupby([\"VisitNumber\", \"Weekday\"], as_index=False).max().TripType\n",
        "    ##display(y)\n",
        "    # we remove the TripType now, and concat training and testing data\n",
        "    # the concat is done so that we have the same columns for both datasets\n",
        "    # after one-hot encoding\n",
        "    df_train = df_train.drop(\"TripType\", axis=1)\n",
        "    df = pd.concat([df_train, df_test])\n",
        "    ##display(df.head(20))\n",
        "    # the next three operations are the ones we have just presented in the previous lines\n",
        "### NUEVO VERSION 3###############\n",
        "#### ACTIVO EL BORRADO   \n",
        "    df.drop_duplicates(keep='first', ignore_index=True, inplace=True)\n",
        "#########################\n",
        "\n",
        "    # drop the columns we won't use (it may be good to use them somehow)\n",
        "    #df = df.drop([\"Upc\"], axis=1)\n",
        "    #################################################\n",
        "    ### NUEVO MELISA\n",
        "    #################################################\n",
        "    mask = df.Upc.isna()\n",
        "    column_name = 'Upc'\n",
        "    df.loc[mask, column_name] = 0\n",
        "    #################################################\n",
        "\n",
        "    mask = (df.FinelineNumber.isna())&(df.DepartmentDescription=='PHARMACY RX')\n",
        "    column_name = 'FinelineNumber'\n",
        "    df.loc[mask, column_name] = 4822.0\n",
        "\n",
        "\n",
        "    # one-hot encoding for the DepartmentDescription\n",
        "### DESACTIVO Y CAMBIO POR LABEL ENCODER...\n",
        "    df = pd.get_dummies(df, columns=[\"DepartmentDescription\"], dummy_na=True)\n",
        "####################################################################################################\n",
        "\n",
        "\n",
        "### NUEVO ###########################################################################################\n",
        "### NO SIRVIÃ“, LO APAGO...Y REACTIVO PANDAS DUMMIES\n",
        "# Create a label (category) encoder object\n",
        "    #le = preprocessing.LabelEncoder()\n",
        "\n",
        "# Fit the encoder to the pandas column\n",
        "    #le.fit(df['DepartmentDescription'].dropna())\n",
        "    #df['D'] = df['DepartmentDescription'].map(lambda x: le.transform([x])[0] if type(x)==str else x) \n",
        "\n",
        "    #df=df.drop([\"DepartmentDescription\"], axis=1)\n",
        "    #df.rename(columns={'D': 'DepartmentDescription'}, inplace=True)\n",
        "#####################################################################################################\n",
        "\n",
        "    # now we add the groupby values\n",
        "    #df = df.groupby([\"VisitNumber\", \"Weekday\",\"FinelineNumber\"], as_index=False).sum()\n",
        "    df = df.groupby([\"VisitNumber\", \"Weekday\"], as_index=False).sum()\n",
        "\n",
        "#### NUEVO - DESACTIVO ESTO... #################################################\n",
        "#    df['tipo_dia']=df.Weekday.apply(lambda x:get_dia_laboral(x))\n",
        "    df = pd.get_dummies(df, columns=[\"Weekday\"], dummy_na=True)\n",
        "\n",
        "#    # finally, we do one-hot encoding for the Weekday\n",
        "#    df = pd.get_dummies(df, columns=[\"Weekday\"], dummy_na=True)\n",
        "################################################################################\n",
        "\n",
        "    # get train and test back\n",
        "    df_train = df[df.is_train_set != 0]\n",
        "    df_test = df[df.is_train_set == 0]\n",
        "    \n",
        "    X = df_train.drop([\"is_train_set\"], axis=1)\n",
        "    yy = None\n",
        "    XX = df_test.drop([\"is_train_set\"], axis=1)\n",
        "\n",
        "    return X, y, XX, yy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSgXf2f2oSBl",
        "colab_type": "text"
      },
      "source": [
        "Load the data..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dButqcNsoSBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y, XX, yy = transform_data(\"https://raw.githubusercontent.com/DiploDatos/AprendizajeSupervisado/master/practico/data/train.csv\", \"https://raw.githubusercontent.com/DiploDatos/AprendizajeSupervisado/master/practico/data/test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jCi-1SroSBq",
        "colab_type": "text"
      },
      "source": [
        "Create the model and evaluate it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqm8xCak7oLS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6863fed3-417d-427b-ec86-53fbfe707cc5"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(67029, 76)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M_sR6mJoSBr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split training dataset into train and \"validation\" \n",
        "# (we won't be using validation set in this example, because of the cross-validation;\n",
        "# but it could be useful for you depending on your approach)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSsG1YyJoSBv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# results dataframe is used to store the computed results\n",
        "results = pd.DataFrame(columns=('clf', 'best_acc'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2meJczmKBb5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "be93b2ca-2f4e-4e0f-e820-6f41c99c14a6"
      },
      "source": [
        "################################################\n",
        "### NUEVO VERSION 4\n",
        "################################################\n",
        "#ASI CORRIÃ“ TODA LA NOCHE Y NO TERMINÃ“\n",
        "#parameters = {\n",
        "#    'n_estimators'      : [50, 75, 100, 120, 149],\n",
        "#    'random_state'      : [2],\n",
        "#    'max_features': ['auto','sqrt','log2'],\n",
        "#    'criterion' :['gini','entropy'],\n",
        "#    'max_depth' : [5,7,9,11,None],\n",
        "#    'min_samples_split': [2, 3, 5, 7],\n",
        "#    'min_samples_leaf': [1, 3, 5, 7],\n",
        "#    'max_leaf_nodes':  [2, 3, 4, 5, 20, 50, 69],\n",
        "#    'oob_score': [True, False],\n",
        "#}\n",
        "\n",
        "######### HAGO UN PEQUEÃ‘O CAMBIO... SINO, LO DEJO COMO ESTABA....###################\n",
        "\n",
        "##################################################################################\n",
        "#parameters = {\n",
        "#    'randomforestclassifier__n_estimators'      : [50, 100, 120, 137, 150],\n",
        "#    'randomforestclassifier__random_state'      : [2],\n",
        "#    'randomforestclassifier__max_features': ['auto','sqrt'],\n",
        "#    'randomforestclassifier__criterion' :['gini','entropy'],\n",
        "#    'randomforestclassifier__max_depth' : [5,7,9,11,None],\n",
        "#    'randomforestclassifier__min_samples_split': [2, 3, 5, 7],\n",
        "#    'randomforestclassifier__min_samples_leaf': [1, 3, 5, 7],\n",
        "#    'randomforestclassifier__max_leaf_nodes':  [2, 3, 5, 7],\n",
        "#    'randomforestclassifier__oob_score': [True, False],\n",
        "#}\n",
        "\n",
        "##################################################################\n",
        "### VERSIÃ“N 2 y 3\n",
        "##################################################################\n",
        "\n",
        "parameters = {\n",
        "    'randomforestclassifier__n_estimators' : [50,100,120],\n",
        "    'randomforestclassifier__random_state' : [2],\n",
        "    'randomforestclassifier__max_features' : ['auto'],\n",
        "    'randomforestclassifier__criterion'    : ['gini','entropy']\n",
        "}\n",
        "\n",
        "with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    model=make_pipeline(StandardScaler(), RandomForestClassifier(random_state=0))\n",
        "    randomtree_clf = GridSearchCV(model, parameters, scoring='accuracy', cv=3)\n",
        "    randomtree_clf.fit(X_train, y_train)\n",
        "    best_tree_clf = randomtree_clf.best_estimator_\n",
        "\n",
        "randomtree_clf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('standardscaler',\n",
              "                                        StandardScaler(copy=True,\n",
              "                                                       with_mean=True,\n",
              "                                                       with_std=True)),\n",
              "                                       ('randomforestclassifier',\n",
              "                                        RandomForestClassifier(bootstrap=True,\n",
              "                                                               ccp_alpha=0.0,\n",
              "                                                               class_weight=None,\n",
              "                                                               criterion='gini',\n",
              "                                                               max_depth=None,\n",
              "                                                               max_features='auto',\n",
              "                                                               max_leaf_nodes=None,\n",
              "                                                               max_samples=None,\n",
              "                                                               min_impurity_decrea...\n",
              "                                                               warm_start=False))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'randomforestclassifier__criterion': ['gini',\n",
              "                                                               'entropy'],\n",
              "                         'randomforestclassifier__max_features': ['auto'],\n",
              "                         'randomforestclassifier__n_estimators': [50, 100, 120],\n",
              "                         'randomforestclassifier__random_state': [2]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcuZHX4wyOe6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "8a9cbde6-fc7c-4323-e99a-6c600074da9c"
      },
      "source": [
        "best_tree_clf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('standardscaler',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('randomforestclassifier',\n",
              "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                        class_weight=None, criterion='gini',\n",
              "                                        max_depth=None, max_features='auto',\n",
              "                                        max_leaf_nodes=None, max_samples=None,\n",
              "                                        min_impurity_decrease=0.0,\n",
              "                                        min_impurity_split=None,\n",
              "                                        min_samples_leaf=1, min_samples_split=2,\n",
              "                                        min_weight_fraction_leaf=0.0,\n",
              "                                        n_estimators=120, n_jobs=None,\n",
              "                                        oob_score=False, random_state=2,\n",
              "                                        verbose=0, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vpk5Eo-KWqpn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "dce9cd5f-f020-40b9-e0e8-0d0567a2bee5"
      },
      "source": [
        "print('Best Decision Tree accuracy: ', randomtree_clf.best_score_)\n",
        "print(randomtree_clf)\n",
        "results = results.append({'clf': randomtree_clf, 'best_acc': randomtree_clf.best_score_}, ignore_index=True)\n",
        "\n",
        "print('The best classifier so far is: ')\n",
        "print(results.loc[results['best_acc'].idxmax()]['clf'])\n",
        "\n",
        "#Kaggle_5=Best Decision Tree accuracy:  0.6910743768773249\n",
        "#The best classifier so far is: \n",
        "#GridSearchCV(cv=3, error_score=nan,\n",
        "#             estimator=Pipeline(memory=None,\n",
        "#                                steps=[('standardscaler',\n",
        "#                                        StandardScaler(copy=True,\n",
        "#                                                       with_mean=True,\n",
        "#                                                       with_std=True)),\n",
        "#                                       ('randomforestclassifier',\n",
        "#                                        RandomForestClassifier(bootstrap=True,\n",
        "#                                                               ccp_alpha=0.0,\n",
        "#                                                               class_weight=None,\n",
        "#                                                               criterion='gini',\n",
        "#                                                               max_depth=None,\n",
        "#                                                               max_features='auto',\n",
        "#                                                               max_leaf_nodes=None,\n",
        "#                                                               max_samples=None,\n",
        "#                                                               min_impurity_decrea...\n",
        "#                                                               warm_start=False))],\n",
        "#                                verbose=False),\n",
        "#             iid='deprecated', n_jobs=None,\n",
        "#             param_grid={'randomforestclassifier__criterion': ['gini',\n",
        "#                                                               'entropy'],\n",
        "#                         'randomforestclassifier__max_features': ['auto'],\n",
        "#                         'randomforestclassifier__n_estimators': [50, 100, 120],\n",
        "#                         'randomforestclassifier__random_state': [2]},\n",
        "#             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
        "#             scoring='accuracy', verbose=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Decision Tree accuracy:  0.6910743768773249\n",
            "GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=Pipeline(memory=None,\n",
            "                                steps=[('standardscaler',\n",
            "                                        StandardScaler(copy=True,\n",
            "                                                       with_mean=True,\n",
            "                                                       with_std=True)),\n",
            "                                       ('randomforestclassifier',\n",
            "                                        RandomForestClassifier(bootstrap=True,\n",
            "                                                               ccp_alpha=0.0,\n",
            "                                                               class_weight=None,\n",
            "                                                               criterion='gini',\n",
            "                                                               max_depth=None,\n",
            "                                                               max_features='auto',\n",
            "                                                               max_leaf_nodes=None,\n",
            "                                                               max_samples=None,\n",
            "                                                               min_impurity_decrea...\n",
            "                                                               warm_start=False))],\n",
            "                                verbose=False),\n",
            "             iid='deprecated', n_jobs=None,\n",
            "             param_grid={'randomforestclassifier__criterion': ['gini',\n",
            "                                                               'entropy'],\n",
            "                         'randomforestclassifier__max_features': ['auto'],\n",
            "                         'randomforestclassifier__n_estimators': [50, 100, 120],\n",
            "                         'randomforestclassifier__random_state': [2]},\n",
            "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
            "             scoring='accuracy', verbose=0)\n",
            "The best classifier so far is: \n",
            "GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=Pipeline(memory=None,\n",
            "                                steps=[('standardscaler',\n",
            "                                        StandardScaler(copy=True,\n",
            "                                                       with_mean=True,\n",
            "                                                       with_std=True)),\n",
            "                                       ('randomforestclassifier',\n",
            "                                        RandomForestClassifier(bootstrap=True,\n",
            "                                                               ccp_alpha=0.0,\n",
            "                                                               class_weight=None,\n",
            "                                                               criterion='gini',\n",
            "                                                               max_depth=None,\n",
            "                                                               max_features='auto',\n",
            "                                                               max_leaf_nodes=None,\n",
            "                                                               max_samples=None,\n",
            "                                                               min_impurity_decrea...\n",
            "                                                               warm_start=False))],\n",
            "                                verbose=False),\n",
            "             iid='deprecated', n_jobs=None,\n",
            "             param_grid={'randomforestclassifier__criterion': ['gini',\n",
            "                                                               'entropy'],\n",
            "                         'randomforestclassifier__max_features': ['auto'],\n",
            "                         'randomforestclassifier__n_estimators': [50, 100, 120],\n",
            "                         'randomforestclassifier__random_state': [2]},\n",
            "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
            "             scoring='accuracy', verbose=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpx2730tBegP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a60ee8b6-c7b5-421c-f245-e39b223ce3e0"
      },
      "source": [
        "predictions = randomtree_clf.predict(X_valid)\n",
        "print ('Accuracy: %d ' % ((np.sum(y_valid == predictions))/float(y_valid.size)*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 69 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2E31NH_Bn-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yy = randomtree_clf.predict(XX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZXmJEYOHNWE",
        "colab_type": "text"
      },
      "source": [
        "Exportamos Resultados\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7X0NZcXHNFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission5 = pd.DataFrame(list(zip(XX.VisitNumber, yy)), columns=[\"VisitNumber\", \"TripType\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-oI8GmrI7sU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission5.to_csv(\"sample_data/submission_randomforest5.csv\", header=True, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}