{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "Kaggle_randomforest.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYoOiEYXoSAJ",
        "colab_type": "text"
      },
      "source": [
        "# Diplodatos Kaggle Competition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeGzAToCoSAK",
        "colab_type": "text"
      },
      "source": [
        "We present this peace of code to create the baseline for the competition, and as an example of how to deal with these kind of problems. The main goals are that you:\n",
        "\n",
        "1. Learn\n",
        "1. Try different models and see which one fits the best the given data\n",
        "1. Get a higher score than the given one in the current baseline example\n",
        "1. Try to get the highest score in the class :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmzh-QKuoSAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the required packages\n",
        "import os\n",
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybqdvn85oSAQ",
        "colab_type": "text"
      },
      "source": [
        "Read the *original* dataset..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YREVk5BLoSAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_df = pd.read_csv('https://raw.githubusercontent.com/DiploDatos/AprendizajeSupervisado/master/practico/data/train.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jgo1zUN-jWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from hashlib import md5\n",
        "def hashit(val):\n",
        "    if isinstance(val, float): \n",
        "        return str(val)\n",
        "    return md5(val.encode('utf-8')).hexdigest()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ymeq3W2P0SD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dia_laboral(nombre_dia):\n",
        "    if nombre_dia in ['Wednesday', 'Thursday', 'Friday', 'Monday','Tuesday']:\n",
        "        return 'Dia laboral'\n",
        "    else:\n",
        "        return 'Fin de semana'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQCLhhEq2Tko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transform_data(train_data_fname, test_data_fname):\n",
        "    df_train = pd.read_csv(train_data_fname)\n",
        "    df_train['is_train_set'] = 1\n",
        "    df_test = pd.read_csv(test_data_fname)\n",
        "    df_test['is_train_set'] = 0\n",
        "\n",
        "    # we  get the TripType for the train set. To do that, we group by VisitNumber and\n",
        "    # then we get the max (or min or avg)\n",
        "    y = df_train.groupby([\"VisitNumber\", \"Weekday\"], as_index=False).max().TripType\n",
        "\n",
        "    # we remove the TripType now, and concat training and testing data\n",
        "    # the concat is done so that we have the same columns for both datasets\n",
        "    # after one-hot encoding\n",
        "    df_train = df_train.drop(\"TripType\", axis=1)\n",
        "    df = pd.concat([df_train, df_test])\n",
        "    \n",
        "    # the next three operations are the ones we have just presented in the previous lines\n",
        "    #df.drop_duplicates(keep='first', ignore_index=True, inplace=True)\n",
        "\n",
        "    # drop the columns we won't use (it may be good to use them somehow)\n",
        "    #df = df.drop([\"Upc\"], axis=1)\n",
        "\n",
        "    mask = (df.FinelineNumber.isna())&(df.DepartmentDescription=='PHARMACY RX')\n",
        "    column_name = 'FinelineNumber'\n",
        "    df.loc[mask, column_name] = 4822.0\n",
        "\n",
        "    # one-hot encoding for the DepartmentDescription\n",
        "    df = pd.get_dummies(df, columns=[\"DepartmentDescription\"], dummy_na=True)\n",
        "\n",
        "    # now we add the groupby values\n",
        "    #df = df.groupby([\"VisitNumber\", \"Weekday\",\"FinelineNumber\"], as_index=False).sum()\n",
        "    df = df.groupby([\"VisitNumber\", \"Weekday\"], as_index=False).sum()\n",
        "\n",
        "    df['tipo_dia']=df.Weekday.apply(lambda x:get_dia_laboral(x))\n",
        "    df = pd.get_dummies(df, columns=[\"tipo_dia\"], dummy_na=True)\n",
        "\n",
        "    # finally, we do one-hot encoding for the Weekday\n",
        "    df = pd.get_dummies(df, columns=[\"Weekday\"], dummy_na=True)\n",
        "\n",
        "    # get train and test back\n",
        "    df_train = df[df.is_train_set != 0]\n",
        "    df_test = df[df.is_train_set == 0]\n",
        "    \n",
        "    X = df_train.drop([\"is_train_set\"], axis=1)\n",
        "    yy = None\n",
        "    XX = df_test.drop([\"is_train_set\"], axis=1)\n",
        "\n",
        "    return X, y, XX, yy"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSgXf2f2oSBl",
        "colab_type": "text"
      },
      "source": [
        "Load the data..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dButqcNsoSBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y, XX, yy = transform_data(\"https://raw.githubusercontent.com/DiploDatos/AprendizajeSupervisado/master/practico/data/train.csv\", \"https://raw.githubusercontent.com/DiploDatos/AprendizajeSupervisado/master/practico/data/test.csv\")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jCi-1SroSBq",
        "colab_type": "text"
      },
      "source": [
        "Create the model and evaluate it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqm8xCak7oLS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9bc0184d-eed8-4a0b-a308-8121509436c8"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(67029, 84)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M_sR6mJoSBr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split training dataset into train and \"validation\" \n",
        "# (we won't be using validation set in this example, because of the cross-validation;\n",
        "# but it could be useful for you depending on your approach)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSsG1YyJoSBv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# results dataframe is used to store the computed results\n",
        "results = pd.DataFrame(columns=('clf', 'best_acc'))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlCvzy1hoSBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we will use a DesicionTree to classify and GridSearch to determine the parameters\n",
        "from sklearn.tree import DecisionTreeClassifier as DT\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2meJczmKBb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#RANDOM FOREST\n",
        "from sklearn import ensemble\n",
        "clf = ensemble.RandomForestClassifier(random_state=2)\n",
        "clf.fit(X_train, y_train);"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjY67DHcGy98",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d0357eb-3870-4278-a1e0-df90870770a3"
      },
      "source": [
        "predictions = clf.predict(X_valid)\n",
        "print ('Accuracy: %d ' % ((np.sum(y_valid == predictions))/float(y_valid.size)*100))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 69 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yHgzXDSoSB4",
        "colab_type": "text"
      },
      "source": [
        "**And finally**, we predict the unknown label for the testing set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiovfAIJG_PF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = clf.predict(XX)\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZXmJEYOHNWE",
        "colab_type": "text"
      },
      "source": [
        "Exportamos Resultados\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7X0NZcXHNFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission2 = pd.DataFrame(list(zip(XX.VisitNumber, predictions)), columns=[\"VisitNumber\", \"TripType\"])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-oI8GmrI7sU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission2.to_csv(\"sample_data/submission_randomforest.csv\", header=True, index=False)"
      ],
      "execution_count": 34,
      "outputs": []
    }
  ]
}